{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuEafBm32r+BufiPELXe/+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadAliMkh/Pytorch/blob/main/food_vision_modular.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.mkdir(\"/content/food_vision_project\")"
      ],
      "metadata": {
        "id": "-vhh2t9fKViV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tv87JVPv99ku",
        "outputId": "5fff73d4-8e5c-42a5-a76a-4781037a5c29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing food_vision_project/fetch_data.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile food_vision_project/fetch_data.py\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "\n",
        "def get_data(zip_file_name , raw_path_url):\n",
        "  \"\"\"\n",
        "  Get zip file from url link\n",
        "\n",
        "    args:\n",
        "      zip_file_name: name of the zip file (include .zip)\n",
        "      raw_path_url: url link that raw zip file (include .zip)\n",
        "    \n",
        "    return:\n",
        "      train_dir: train direcotry path\n",
        "      test_dir: test directory path\n",
        "  \"\"\"\n",
        "\n",
        "  file_name = zip_file_name\n",
        "  folder_name = file_name.split(\".zip\")[0]\n",
        "\n",
        "  parent_dir = Path.cwd()\n",
        "  data_dir = parent_dir/folder_name\n",
        "\n",
        "  if Path.exists(data_dir):\n",
        "    print(f\"{folder_name} Folder Already Exists...\")\n",
        "  else:\n",
        "    os.makedirs(data_dir)\n",
        "    print(f\"{folder_name} Folder Created...\")\n",
        "\n",
        "\n",
        "\n",
        "  # get pizza_steak_sushi.zip file from mrdbourrke github repository\n",
        "  r = requests.get(raw_path_url)\n",
        "\n",
        "  with open(file_name , \"wb\") as f:\n",
        "    f.write(r.content)\n",
        "\n",
        "  data_path = parent_dir/file_name\n",
        "  print(f\"{file_name} downloaded...\")\n",
        "\n",
        "\n",
        "\n",
        "  # loading the temp.zip and creating a zip object\n",
        "  with ZipFile(data_path , 'r') as zObject:\n",
        "    \n",
        "      # Extracting all the members of the zip \n",
        "      # into a specific location.\n",
        "      zObject.extractall(\n",
        "          path=data_dir)\n",
        "  print(f\"{file_name} extracted at {data_dir}\")\n",
        "  # removing the downloaded.zip file from parent directory\n",
        "  os.remove(data_path)\n",
        "\n",
        "  train_dir = data_dir/\"train\"\n",
        "  test_dir = data_dir/\"test\"\n",
        "\n",
        "  return train_dir , test_dir"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from food_vision_project import fetch_data\n",
        "train_dir , test_dir = fetch_data.get_data(\"pizza_steak_sushi.zip\" , \"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")"
      ],
      "metadata": {
        "id": "gxC3qJ6NLMkT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b041869-f177-4467-ed07-9a43253ad7c5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pizza_steak_sushi Folder Created...\n",
            "pizza_steak_sushi.zip downloaded...\n",
            "pizza_steak_sushi.zip extracted at /content/pizza_steak_sushi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile food_vision_project/data_setup.py\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def create_dataLoader(train_dir:Path,\n",
        "                      test_dir:Path,\n",
        "                      batch_size:int,\n",
        "                      transformer:transforms.Compose):\n",
        "  '''\n",
        "    Make test/train data Loder object\n",
        "\n",
        "    inputs:\n",
        "      train_dir: train data directory\n",
        "      test_dir: test data directory\n",
        "      batch_size: batch size of the dataLoader\n",
        "      transformer: transforms.Compose object \n",
        "    \n",
        "    return:\n",
        "      train_dataLoader: torch.utils.data.DataLoader object\n",
        "      test_dataLoader: torch.utils.data.DataLoader object\n",
        "      class_names: list of the all class names\n",
        "  '''\n",
        "\n",
        "  BATCH_SIZE = batch_size\n",
        "  TRAIN_DIR = train_dir\n",
        "  TEST_DIR = test_dir\n",
        "  NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "  TRANSFORMER = transformer\n",
        "\n",
        "\n",
        "\n",
        "  train_dataset = ImageFolder(TRAIN_DIR , transform = TRANSFORMER)\n",
        "  test_dataset = ImageFolder(TEST_DIR , transform = TRANSFORMER)\n",
        "\n",
        "\n",
        "  train_dataLoader = DataLoader(train_dataset ,\n",
        "                                batch_size = BATCH_SIZE,\n",
        "                                shuffle = True,\n",
        "                                num_workers = NUM_WORKERS,\n",
        "                                pin_memory = True)\n",
        "\n",
        "  test_dataLoader = DataLoader(test_dataset,\n",
        "                              batch_size = BATCH_SIZE,\n",
        "                              shuffle = False,\n",
        "                              num_workers = NUM_WORKERS,\n",
        "                              pin_memory=True)\n",
        "  \n",
        "  class_names = train_dataset.classes\n",
        "  \n",
        "\n",
        "  return train_dataLoader , test_dataLoader , class_names\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFoD9N5C8qqV",
        "outputId": "def42a0f-f215-421b-e95e-f28609ef496b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing food_vision_project/data_setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "transfomer = transforms.Compose([\n",
        "    transforms.Resize(size = (64 , 64)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "7345hCEZcLWp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from food_vision_project import data_setup\n",
        "x , y , z = data_setup.create_dataLoader(train_dir , test_dir , batch_size = 32 , transformer = transfomer)"
      ],
      "metadata": {
        "id": "oYHgoBBrb56T"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile food_vision_project/model.py\n",
        "import torch\n",
        "\n",
        "Conv_Kernel_Size = 3\n",
        "Conv_Stride_Size = 1\n",
        "Conv_Padding_Size = 0\n",
        "\n",
        "Max_Kernel_Size = 2\n",
        "Max_Stride_Size = 1\n",
        "\n",
        "class TinyVGG(torch.nn.Module):\n",
        "  ''' \n",
        "    Tiny VGG Network created from https://poloclub.github.io/cnn-explainer/\n",
        "  '''\n",
        "\n",
        "  def __init__(self , input_size:int , hidden_units:int , output_shape:int):\n",
        "    super().__init__();\n",
        "    self.conv_block1 = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(in_channels = input_size , out_channels = hidden_units,\n",
        "                        kernel_size = Conv_Kernel_Size ,stride = Conv_Stride_Size,\n",
        "                        padding = Conv_Padding_Size),\n",
        "\n",
        "        torch.nn.ReLU(),\n",
        "\n",
        "        torch.nn.Conv2d(in_channels = hidden_units , out_channels = hidden_units,\n",
        "                        kernel_size = Conv_Kernel_Size ,stride = Conv_Stride_Size,\n",
        "                        padding = Conv_Padding_Size),\n",
        "        torch.nn.ReLU(),\n",
        "\n",
        "        torch.nn.MaxPool2d(kernel_size = Max_Kernel_Size ,stride = Max_Stride_Size)\n",
        "    )\n",
        "\n",
        "    self.conv_block2 = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(in_channels = hidden_units , out_channels = hidden_units,\n",
        "                        kernel_size = Conv_Kernel_Size , stride = Conv_Stride_Size , padding = Conv_Padding_Size),\n",
        "\n",
        "        torch.nn.ReLU(),\n",
        "\n",
        "        torch.nn.Conv2d(in_channels = hidden_units , out_channels = hidden_units,\n",
        "                        kernel_size = Conv_Kernel_Size , stride = Conv_Stride_Size , padding = Conv_Padding_Size),\n",
        "\n",
        "        torch.nn.ReLU(),\n",
        "\n",
        "        torch.nn.MaxPool2d(kernel_size = Max_Kernel_Size , stride  = Max_Stride_Size)\n",
        "    )\n",
        "\n",
        "    self.last_layer = torch.nn.Sequential(\n",
        "        torch.nn.Flatten(),\n",
        "\n",
        "        torch.nn.Linear(in_features = hidden_units * 54 * 54, out_features=output_shape)\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self , x):\n",
        "    x = self.conv_block1(x)\n",
        "    #print(x.shape)\n",
        "    x = self.conv_block2(x)\n",
        "    #print(x.shape)\n",
        "    x = self.last_layer(x)\n",
        "    #print(x.shape)\n",
        "    return x\n",
        "    "
      ],
      "metadata": {
        "id": "idmTnjK8c9d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da5b98b4-9643-4f82-d9c6-0066114389a7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting food_vision_project/model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "bWAgLp1nXVfw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from food_vision_project import model\n",
        "\n",
        "cnn = model.TinyVGG(input_size = 3 , hidden_units = 10 , output_shape = 3).to(device)"
      ],
      "metadata": {
        "id": "wPrRZwWpXmwn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(cnn.parameters() , lr = 0.001)"
      ],
      "metadata": {
        "id": "Dpq75H6MYkPm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile food_vision_project/engine.py\n",
        "\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def train_model(model:torch.nn.Module,\n",
        "                data:torch.utils.data.DataLoader,\n",
        "                loss_fn:torch.nn.Module,\n",
        "                optimizer:torch.optim.Optimizer,\n",
        "                device = device):\n",
        "  '''\n",
        "    Train Model on Each Epoch and Return Train Accuracy and Loss\n",
        "\n",
        "    args: \n",
        "        model: torch.nn.Module\n",
        "        data: torch.utils.data.DataLoader (train data)\n",
        "        loss_fn: torch.nn.Module\n",
        "        optimizer: torch.optim\n",
        "        device: device agnostic parameter (cpu or cuda)\n",
        "\n",
        "    outputs:\n",
        "        acc: List of accuracies in each batch trained\n",
        "        loss: List of losses in each batch traind\n",
        "  '''\n",
        "  \n",
        "  accuracy = []\n",
        "  loss = []\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for batch , (X , y) in enumerate(data):\n",
        "\n",
        "    X , y = X.to(device) , y.to(device)\n",
        "\n",
        "    train_logits = model(X)\n",
        "\n",
        "    train_loss = loss_fn(train_logits , y)\n",
        "    loss.append(train_loss.item())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    train_loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    train_predicts = torch.argmax(torch.softmax(train_logits , dim = 1) , dim = 1)\n",
        "    train_accuracy = sum(train_predicts == y for train_predicts , y in zip(train_predicts , y))/len(y)\n",
        "    accuracy.append(train_accuracy)\n",
        "  \n",
        "  acc = sum(accuracy)/len(data)\n",
        "  loss = sum(loss)/len(data)\n",
        "\n",
        "  return acc.item()*100 , loss\n",
        "\n",
        "\n",
        "def test_model(model:torch.nn.Module,\n",
        "               data:torch.utils.data.DataLoader,\n",
        "               loss_fn:torch.nn.Module,\n",
        "               device = device):\n",
        "  '''\n",
        "    Test Model on Each Batch and Return Test Accuracy/Loss\n",
        "\n",
        "    args:\n",
        "        model: torch.nn.Module\n",
        "        data: torch.utils.data.DataLoader (test data)\n",
        "        loss_fn: torch.nn.Module\n",
        "        device: device agnostic parameter (cpu or cuda)\n",
        "\n",
        "    outputs:\n",
        "        acc: List of test accuracies in each test batch\n",
        "        loss: List of test losses in each test batch\n",
        "  '''\n",
        "  \n",
        "  accuracy = []\n",
        "  loss = []\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for batch , (X , y) in enumerate(data):\n",
        "      X , y = X.to(device) , y.to(device)\n",
        "\n",
        "      test_logits = model(X)\n",
        "\n",
        "      test_loss = loss_fn(test_logits , y)\n",
        "      loss.append(test_loss)\n",
        "\n",
        "      test_predicts = torch.argmax(torch.softmax(test_logits , dim = 1) , dim = 1)\n",
        "      test_accuracy = sum(test_predicts == y for test_predicts , y in zip(test_predicts , y)) / len(y)\n",
        "      accuracy.append(test_accuracy)\n",
        "    \n",
        "    acc = sum(accuracy) / len(data)\n",
        "    loss = sum(loss) / len(data)\n",
        "\n",
        "    return acc.item() * 100 , loss.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm87Lz6QWTb0",
        "outputId": "666900a8-dfae-4234-8f0e-949cc4eab9fc"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting food_vision_project/engine.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sqrIRrhyeHT8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}