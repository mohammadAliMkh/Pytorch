{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env bash\n",
        "\n",
        "## DOWNLOAD from JOSEPHS WEBSITE (SLOWER DOWNLOAD)\n",
        "#wget https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar\n",
        "#wget https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n",
        "#wget https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar\n",
        "\n",
        "## OR DOWNLOAD FROM HERE (FASTER DOWNLOAD)\n",
        "# VOC2007 DATASET\n",
        "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
        "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
        "\n",
        "# VOC2012 DATASET\n",
        "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JF40maG__QR5",
        "outputId": "909da03a-81d8-4514-919f-ce0ad0b33e5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-16 12:28:20--  http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
            "Resolving host.robots.ox.ac.uk (host.robots.ox.ac.uk)... 129.67.94.152\n",
            "Connecting to host.robots.ox.ac.uk (host.robots.ox.ac.uk)|129.67.94.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 460032000 (439M) [application/x-tar]\n",
            "Saving to: ‘VOCtrainval_06-Nov-2007.tar’\n",
            "\n",
            "VOCtrainval_06-Nov- 100%[===================>] 438.72M  18.6MB/s    in 19s     \n",
            "\n",
            "2025-02-16 12:28:39 (22.9 MB/s) - ‘VOCtrainval_06-Nov-2007.tar’ saved [460032000/460032000]\n",
            "\n",
            "--2025-02-16 12:28:39--  http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
            "Resolving host.robots.ox.ac.uk (host.robots.ox.ac.uk)... 129.67.94.152\n",
            "Connecting to host.robots.ox.ac.uk (host.robots.ox.ac.uk)|129.67.94.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 451020800 (430M) [application/x-tar]\n",
            "Saving to: ‘VOCtest_06-Nov-2007.tar’\n",
            "\n",
            "VOCtest_06-Nov-2007 100%[===================>] 430.13M  17.6MB/s    in 28s     \n",
            "\n",
            "2025-02-16 12:29:08 (15.2 MB/s) - ‘VOCtest_06-Nov-2007.tar’ saved [451020800/451020800]\n",
            "\n",
            "--2025-02-16 12:29:08--  http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n",
            "Resolving host.robots.ox.ac.uk (host.robots.ox.ac.uk)... 129.67.94.152\n",
            "Connecting to host.robots.ox.ac.uk (host.robots.ox.ac.uk)|129.67.94.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1999639040 (1.9G) [application/x-tar]\n",
            "Saving to: ‘VOCtrainval_11-May-2012.tar’\n",
            "\n",
            "VOCtrainval_11-May- 100%[===================>]   1.86G  27.8MB/s    in 80s     \n",
            "\n",
            "2025-02-16 12:30:28 (23.9 MB/s) - ‘VOCtrainval_11-May-2012.tar’ saved [1999639040/1999639040]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract tar files\n",
        "!tar xf VOCtrainval_11-May-2012.tar\n",
        "!tar xf VOCtrainval_06-Nov-2007.tar\n",
        "!tar xf VOCtest_06-Nov-2007.tar\n",
        "\n",
        "# Need voc_label.py to clean up data from xml files\n",
        "#!wget https://pjreddie.com/media/files/voc_label.py"
      ],
      "metadata": {
        "id": "em91R8DmCHyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run python file to clean data from xml files\n",
        "!python voc_label.py"
      ],
      "metadata": {
        "id": "1KDPBBbrGW1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get train by using train+val from 2007 and 2012\n",
        "# Then we only test on 2007 test set\n",
        "# Unclear from paper what they actually just as a dev set\n",
        "!cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt\n",
        "!cp 2007_test.txt test.txt"
      ],
      "metadata": {
        "id": "qn7S2lHWG-ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move txt files we won't be using to clean up a little bit\n",
        "!mkdir old_txt_files\n",
        "!mv 2007* 2012* old_txt_files/"
      ],
      "metadata": {
        "id": "ENuZYOWFHQ-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_csv.py"
      ],
      "metadata": {
        "id": "CbMsC0fsHZW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!mkdir data/images\n",
        "!mkdir data/labels"
      ],
      "metadata": {
        "id": "706f022bNgrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv VOCdevkit/VOC2007/JPEGImages/*.jpg data/images/\n",
        "!mv VOCdevkit/VOC2012/JPEGImages/*.jpg data/images/\n",
        "!mv VOCdevkit/VOC2007/labels/*.txt data/labels/\n",
        "!mv VOCdevkit/VOC2012/labels/*.txt data/labels/"
      ],
      "metadata": {
        "id": "o60xe7-xKpqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf VOCdevkit/\n",
        "!mv test.txt old_txt_files/\n",
        "!mv train.txt old_txt_files/"
      ],
      "metadata": {
        "id": "dd8Xhi2MJ6Ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#our train_data includes of:\n",
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "print(f\"number of train data: {len(train)}\")\n",
        "print(f\"number of test data: {len(test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5FkLb8gSwlP",
        "outputId": "e4f88823-863f-4e03-c33a-074dbc5fb7f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of train data: 16550\n",
            "number of test data: 4951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Main file for training Yolo model on Pascal VOC dataset\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms.functional as FT\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from model import Yolov1\n",
        "from dataset import VOCDataset\n",
        "from utils import (\n",
        "    non_max_suppression,\n",
        "    mean_average_precision,\n",
        "    intersection_over_union,\n",
        "    cellboxes_to_boxes,\n",
        "    get_bboxes,\n",
        "    plot_image,\n",
        "    save_checkpoint,\n",
        "    load_checkpoint,\n",
        ")\n",
        "from loss import YoloLoss\n",
        "\n",
        "seed = 123\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# Hyperparameters etc.\n",
        "LEARNING_RATE = 2e-5\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
        "BATCH_SIZE = 16 # 64 in original paper but I don't have that much vram, grad accum?\n",
        "WEIGHT_DECAY = 0\n",
        "EPOCHS = 1000\n",
        "NUM_WORKERS = 2\n",
        "PIN_MEMORY = True\n",
        "LOAD_MODEL = False\n",
        "LOAD_MODEL_FILE = \"overfit.pth.tar\"\n",
        "IMG_DIR = \"data/images\"\n",
        "LABEL_DIR = \"data/labels\"\n",
        "\n",
        "\n",
        "class Compose(object):\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, img, bboxes):\n",
        "        for t in self.transforms:\n",
        "            img, bboxes = t(img), bboxes\n",
        "\n",
        "        return img, bboxes\n",
        "\n",
        "\n",
        "transform = Compose([transforms.Resize((448, 448)), transforms.ToTensor(),])\n",
        "\n",
        "\n",
        "def train_fn(train_loader, model, optimizer, loss_fn):\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    mean_loss = []\n",
        "\n",
        "    for batch_idx, (x, y) in enumerate(loop):\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "        out = model(x)\n",
        "        loss = loss_fn(out, y)\n",
        "        mean_loss.append(loss.item())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # update progress bar\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    print(f\"Mean loss was {sum(mean_loss)/len(mean_loss)}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    model = Yolov1(split_size=7, num_boxes=2, num_classes=20).to(DEVICE)\n",
        "    optimizer = optim.Adam(\n",
        "        model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
        "    )\n",
        "    loss_fn = YoloLoss()\n",
        "\n",
        "    if LOAD_MODEL:\n",
        "        load_checkpoint(torch.load(LOAD_MODEL_FILE), model, optimizer)\n",
        "\n",
        "    train_dataset = VOCDataset(\n",
        "        \"train.csv\",\n",
        "        transform=transform,\n",
        "        img_dir=IMG_DIR,\n",
        "        label_dir=LABEL_DIR,\n",
        "    )\n",
        "\n",
        "    test_dataset = VOCDataset(\n",
        "        \"test.csv\", transform=transform, img_dir=IMG_DIR, label_dir=LABEL_DIR,\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        dataset=train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=PIN_MEMORY,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        dataset=test_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=PIN_MEMORY,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        # for x, y in train_loader:\n",
        "        #    x = x.to(DEVICE)\n",
        "        #    for idx in range(8):\n",
        "        #        bboxes = cellboxes_to_boxes(model(x))\n",
        "        #        bboxes = non_max_suppression(bboxes[idx], iou_threshold=0.5, threshold=0.4, box_format=\"midpoint\")\n",
        "        #        plot_image(x[idx].permute(1,2,0).to(\"cpu\"), bboxes)\n",
        "\n",
        "        #    import sys\n",
        "        #    sys.exit()\n",
        "\n",
        "        pred_boxes, target_boxes = get_bboxes(\n",
        "            train_loader, model, iou_threshold=0.5, threshold=0.4\n",
        "        )\n",
        "\n",
        "        mean_avg_prec = mean_average_precision(\n",
        "            pred_boxes, target_boxes, iou_threshold=0.5, box_format=\"midpoint\"\n",
        "        )\n",
        "        print(f\"Train mAP: {mean_avg_prec}\")\n",
        "\n",
        "        #if mean_avg_prec > 0.9:\n",
        "        #    checkpoint = {\n",
        "        #        \"state_dict\": model.state_dict(),\n",
        "        #        \"optimizer\": optimizer.state_dict(),\n",
        "        #    }\n",
        "        #    save_checkpoint(checkpoint, filename=LOAD_MODEL_FILE)\n",
        "        #    import time\n",
        "        #    time.sleep(10)\n",
        "\n",
        "        train_fn(train_loader, model, optimizer, loss_fn)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "E4pYmDRPtKIR",
        "outputId": "0d6ca8f7-a860-47e3-8a2b-1fbbf61c6763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train mAP: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1034/1034 [05:57<00:00,  2.89it/s, loss=247]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean loss was 212.691597346411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train mAP: 0.003582685487344861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 233/1034 [01:19<04:33,  2.93it/s, loss=169]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-f99cc1b0777a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-f99cc1b0777a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m#    time.sleep(10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-f99cc1b0777a>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(train_loader, model, optimizer, loss_fn)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# update progress bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Mean loss was {sum(mean_loss)/len(mean_loss)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cc_cYINduTmx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}